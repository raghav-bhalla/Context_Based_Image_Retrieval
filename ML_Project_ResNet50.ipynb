{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Project_ResNet50",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Group - 21**\n",
        "\n",
        "1) Raghav Bhalla (2019379)\n",
        "\n",
        "2) Ritesh Panwar (2019384) "
      ],
      "metadata": {
        "id": "WQ7K7DRKGzr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RESNET50 Deep CNN model**"
      ],
      "metadata": {
        "id": "L4ebwOmbG1Mb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4PlrqyAgXpS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from sklearn.cluster import KMeans\n",
        "import configparser\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pickle\n",
        "import shutil\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML\n",
        "import random\n",
        "from urllib.parse import urlparse\n",
        "from scipy.spatial.distance import cityblock\n",
        "import cv2\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from pathlib import Path\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2IgQxcSs1jQ",
        "outputId": "0801dac3-90df-4ac6-e7df-9b6798c019f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "images_file_path = '/content/drive/MyDrive/data/images_array'\n",
        "with open(images_file_path, 'rb') as f:\n",
        "    images_Arr = pickle.load(f)"
      ],
      "metadata": {
        "id": "G1KDZySQsyFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_train = images_Arr[:7500]\n",
        "image_test = images_Arr[7500:]"
      ],
      "metadata": {
        "id": "a-Pzgz8LtHpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inp = []\n",
        "\n",
        "for i in range(0, len(image_train)):\n",
        "  # Resizing the image for VGG16 model architecture, and also converting the color space of image\n",
        "  img_temp= image_train[i].resize((100, 100))\n",
        "  img_temp = img_temp.convert('RGB')\n",
        "  train_inp.append(np.array(img_temp))"
      ],
      "metadata": {
        "id": "SNe98xc8tINy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_inp = []\n",
        "\n",
        "for i in range(0, len(image_test)):\n",
        "  # Resizing the image for VGG16 model architecture, and also converting the color space of image\n",
        "  img_temp = image_test[i].resize((100, 100))\n",
        "  img_temp = img_temp.convert('RGB')\n",
        "  test_inp.append(np.array(img_temp))"
      ],
      "metadata": {
        "id": "UldaAgF8tLo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inp[1].shape"
      ],
      "metadata": {
        "id": "Um6LUZ0KtV3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5bef287-1383-46af-d8ce-ea042ca99fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = 100\n",
        "w = 100\n",
        "nc = 3\n",
        "IN = Input(shape = (h,w,nc))\n",
        "model = ResNet50(include_top = False, weights='imagenet', input_tensor=IN)\n",
        "model = Model(inputs = model.input, outputs = model.get_layer('conv5_block3_2_relu').output)"
      ],
      "metadata": {
        "id": "VfAuFZ64guaL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ebd7f49-19d0-4676-d614-2be95e6fedf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_train_curr = image_train[3].resize((100, 100))\n",
        "img = image.img_to_array(images_train_curr)\n",
        "img = np.expand_dims(img, axis=0)\n",
        "img = preprocess_input(img)\n",
        "img.shape\n",
        "feature = model.predict(img)[0]\n",
        "print(feature.shape)\n",
        "feature = feature.flatten()\n",
        "print(feature.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBpsW5Qf1Dkk",
        "outputId": "dc0c7fb9-4a68-48ad-bc1b-73ef9ce41ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 4, 512)\n",
            "(8192,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only run if features not extracted"
      ],
      "metadata": {
        "id": "ktwZwAJsId6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_Arr = []\n",
        "\n",
        "#Iterating over each image in database to obtain features\n",
        "for i in range(0, len(image_train)):\n",
        "\n",
        "  # Resizing the image for VGG16 model architecture, and also converting the color space of image\n",
        "  images_train_curr = image_train[i].resize((100, 100))\n",
        "  # print(type(images_train_curr))\n",
        "  # images_train_curr = np.resize(images_train[i], (224, 224))\n",
        "  # print(type(images_train_curr))\n",
        "  images_train_curr = images_train_curr.convert('RGB')\n",
        "\n",
        "  # Reformat and preprocessing the image\n",
        "  img = image.img_to_array(images_train_curr)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  img = preprocess_input(img)\n",
        "\n",
        "  # Extracting features of current index image\n",
        "  feature = model.predict(img)[0]\n",
        "  feature_norm = np.linalg.norm(feature)\n",
        "  feature /= feature_norm\n",
        "\n",
        "  # Appeding the features of current index image in features array\n",
        "  features_Arr.append(feature.flatten())\n",
        "\n",
        "\n",
        "feature_path = \"features.npy\"\n",
        "np.save(feature_path, features_Arr)\n",
        "\n",
        "#For saving in Gdrive\n",
        "feature_path = \"/content/drive/My Drive/Images_ML/features_RESNET50.npy\"\n",
        "np.save(feature_path, features_Arr)"
      ],
      "metadata": {
        "id": "1Hu_KEXUgc9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# features_Arr"
      ],
      "metadata": {
        "id": "dT__dt3O0jzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(num_images, similar_images):\n",
        "\n",
        "  #Displaying Similar Images with the distance metric\n",
        "  axes=[]\n",
        "  figure = plt.figure(figsize=(18,14), edgecolor='black')\n",
        "\n",
        "  for i in range(num_images):\n",
        "      axes.append(figure.add_subplot(4, 5, i+1))\n",
        "      rank = 'Rank-' + str(i+1)\n",
        "      axes[-1].set_title(rank + '\\nScore: '+ str(similar_images[i][0]))  \n",
        "      plt.imshow(similar_images[i][1])\n",
        "      plt.axis('off')\n",
        "      # display(similar_images[i][1])\n",
        "  \n",
        "  figure.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "O2Iqx_k0zzo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Euclidean distance between features of each image in database with the query image\n",
        "def euclidian_dist(features, query_feature):\n",
        "  euclidean_dists = np.linalg.norm(features - query_feature, axis=1)\n",
        "  return euclidean_dists\n",
        "\n",
        "#Cosine Similarity between features of each image in database with the query image\n",
        "def cosine_similarity(features, query_feature):\n",
        "  cosine_similarity_scores = features.dot(query_feature) / (np.linalg.norm(features, axis=1) * np.linalg.norm(query_feature))\n",
        "  return cosine_similarity_scores\n",
        "\n",
        "#Manhattan distance between features of each image in database with the query image\n",
        "def manhattan_dist(features, query_feature):\n",
        "  manhattan_dists = []\n",
        "  for i in range(len(features)):\n",
        "    manhattan_dists.append(cityblock(features[i], query_feature))\n",
        "  return np.array(manhattan_dists)"
      ],
      "metadata": {
        "id": "BRkC11T2z7OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_similar_images(index, num_images, eval_metric):\n",
        "\n",
        "  #Displaying query Image first\n",
        "  print(\"Query Image :\")\n",
        "  query_img = image_test[index]\n",
        "  display(query_img)\n",
        "  print('--------------------------------\\n')\n",
        "\n",
        "  #extracting features of query file\n",
        "  # Resizing the image for VGG16 model architecture, and also converting the color space of image\n",
        "  query_img = query_img.resize((100, 100))\n",
        "  query_img = query_img.convert('RGB')\n",
        "\n",
        "  # Reformat and preprocessing the image\n",
        "  img = image.img_to_array(query_img)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  img = preprocess_input(img)\n",
        "\n",
        "  # Extracting features of current index image\n",
        "  query_feature = model.predict(img)[0]\n",
        "  query_feature = query_feature.flatten()\n",
        "  query_feature_norm = np.linalg.norm(query_feature)\n",
        "  query_feature /= query_feature_norm\n",
        "\n",
        "  features_file_path = \"/content/drive/My Drive/data/features_RESNET50.npy\"\n",
        "  features = np.load(features_file_path)\n",
        "\n",
        "  #Computing similarity/distances between query image and all images based on extracted features\n",
        "  #Also sorting resultant metrics to get top k similar images\n",
        "  if eval_metric == 'cosine':\n",
        "    metric = cosine_similarity(features, query_feature)\n",
        "    similar_images_index = np.flip(np.argsort(metric))[:num_images]\n",
        "  elif eval_metric == 'manhattan':\n",
        "    metric = manhattan_dist(features, query_feature)\n",
        "    similar_images_index = np.argsort(metric)[:num_images]\n",
        "  else:\n",
        "    metric = euclidian_dist(features, query_feature)\n",
        "    similar_images_index = np.argsort(metric)[:num_images]\n",
        "\n",
        "  similar_images = []\n",
        "  for i in similar_images_index:\n",
        "    similar_images.append((round(metric[i],5), image_train[i]))\n",
        "\n",
        "  #Displaying Similar Images with the distance metric\n",
        "  print('Similar Images')\n",
        "  plot_images(num_images, similar_images)\n"
      ],
      "metadata": {
        "id": "a1c9tTA9z99O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = int(input(\"Enter Input Index: \"))\n",
        "num_images = int(input(\"Enter Number of Similar Images to be predicted (Upto 20): \"))\n",
        "\n",
        "print('\\n')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('\\033[1m' + '\\t SIMILAR IMAGES BASED ON MANHATTAN DISTANCE' + '\\033[0m')\n",
        "print('------------------------------------------------------------------------')\n",
        "predict_similar_images(index, num_images, 'manhattan')\n",
        "\n",
        "print('\\n')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('\\033[1m' + '\\t SIMILAR IMAGES BASED ON EUCLIDEAN DISTANCE' + '\\033[0m')\n",
        "print('------------------------------------------------------------------------')\n",
        "predict_similar_images(index, num_images, 'euclidean')\n",
        "\n",
        "print('\\n')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('\\033[1m' + '\\t SIMILAR IMAGES BASED ON COSINE SIMILARITY' + '\\033[0m')\n",
        "print('------------------------------------------------------------------------')\n",
        "predict_similar_images(index, num_images, 'cosine')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FVevD8v0Ev9",
        "outputId": "4f14c875-20d2-4db6-8f75-9887c32c54ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Input Index: 200\n",
            "Enter Number of Similar Images to be predicted (Upto 20): 5\n"
          ]
        }
      ]
    }
  ]
}